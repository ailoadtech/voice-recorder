# Voice Intelligence Desktop App - Environment Variables

# =============================================================================
# API Keys
# =============================================================================

# OpenAI API Key for Whisper (transcription) and GPT (enrichment)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# Alternative: If using separate keys for different services
# WHISPER_API_KEY=sk-your-whisper-api-key-here
# GPT_API_KEY=sk-your-gpt-api-key-here

# =============================================================================
# AI Model Configuration
# =============================================================================

# Whisper model to use for transcription
# Options: whisper-1 (default)
NEXT_PUBLIC_WHISPER_MODEL=whisper-1

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# LLM provider to use for text enrichment
# Options: openai (default), ollama
# - openai: Uses OpenAI's GPT API (requires OPENAI_API_KEY)
# - ollama: Uses a remote/local Ollama server (requires OLLAMA_BASE_URL)
LLM_PROVIDER=openai

# --- OpenAI Provider Settings ---
# GPT model to use for text enrichment when using OpenAI provider
# Options: gpt-4, gpt-4-turbo, gpt-3.5-turbo
NEXT_PUBLIC_GPT_MODEL=gpt-4

# GPT temperature (0.0 - 2.0, default: 0.7)
# Lower values make output more focused and deterministic
GPT_TEMPERATURE=0.7

# GPT max tokens (default: 1000)
# Maximum number of tokens to generate in the response
GPT_MAX_TOKENS=1000

# --- Ollama Provider Settings ---
# Ollama server base URL
# Default: http://localhost:11434
# Examples:
#   - Local server: http://localhost:11434
#   - Remote server: http://192.168.1.100:11434
#   - Remote server with custom port: http://ollama.example.com:8080
OLLAMA_BASE_URL=http://localhost:11434

# Ollama model to use for text enrichment
# Default: llama2
# Popular options:
#   - llama2: Meta's Llama 2 model (7B, 13B, 70B variants)
#   - llama3: Meta's Llama 3 model (8B, 70B variants)
#   - mistral: Mistral AI's model (7B)
#   - mixtral: Mistral AI's mixture of experts model (8x7B)
#   - codellama: Code-specialized Llama model
#   - phi: Microsoft's Phi model (2.7B, 3B variants)
# Note: Model must be pulled on the Ollama server first using: ollama pull <model-name>
OLLAMA_MODEL=llama2

# Ollama request timeout in milliseconds (default: 30000)
# Increase this value for larger models or slower hardware
OLLAMA_TIMEOUT=30000

# =============================================================================
# Application Settings
# =============================================================================

# Global hotkey combination for recording activation
# Format: CommandOrControl+Shift+R (cross-platform)
# Windows/Linux: Ctrl+Shift+R, macOS: Cmd+Shift+R
NEXT_PUBLIC_HOTKEY_COMBINATION=CommandOrControl+Shift+R

# Application environment
# Options: development, production
NODE_ENV=development

# =============================================================================
# API Configuration (Optional)
# =============================================================================

# OpenAI API base URL (optional, for custom endpoints)
NEXT_PUBLIC_OPENAI_API_BASE_URL=https://api.openai.com/v1

# API request timeout in milliseconds
NEXT_PUBLIC_API_TIMEOUT=30000

# Maximum retries for failed API requests
NEXT_PUBLIC_API_MAX_RETRIES=3

# =============================================================================
# Storage Configuration (Optional)
# =============================================================================

# Local storage path for recordings (relative to app data directory)
NEXT_PUBLIC_STORAGE_PATH=recordings

# Maximum number of recordings to keep in history
NEXT_PUBLIC_MAX_HISTORY_ITEMS=100

# =============================================================================
# Audio Configuration (Optional)
# =============================================================================

# Audio recording format
# Options: webm, mp3, wav
NEXT_PUBLIC_AUDIO_FORMAT=webm

# Audio quality/bitrate
NEXT_PUBLIC_AUDIO_BITRATE=128000

# =============================================================================
# Feature Flags (Optional)
# =============================================================================

# Enable/disable automatic enrichment after transcription
NEXT_PUBLIC_AUTO_ENRICH=false

# Enable/disable system tray integration
NEXT_PUBLIC_ENABLE_SYSTEM_TRAY=true

# Enable/disable startup on boot
NEXT_PUBLIC_STARTUP_ON_BOOT=false

# Enable/disable telemetry (with user consent)
NEXT_PUBLIC_ENABLE_TELEMETRY=false

# =============================================================================
# Development Settings (Optional)
# =============================================================================

# Enable debug logging
NEXT_PUBLIC_DEBUG=false

# Log level: error, warn, info, debug
NEXT_PUBLIC_LOG_LEVEL=info
